# 9.1 Apache Flink ML 简介

## 什么是Flink-ML

Apache FlinkML是Flink的机器学习(ML)库, 对应Apache Flink代码的flink-libraries/flink-ml模块。 FlinkML的目标是提供可扩展的ML算法，直观的API和工具，以最小的成本构建端到端ML系统。

## Flink-ML 算法分类

正如Murphy [1]所定义的那样，ML涉及检测数据中的模式，并使用这些学习模式来预测未来。我们可以将大多数ML算法分为两大类：监督和非监督学习。

* Supervised Learning

  监督学习涉及学习从一组输入（特征）到一组输出的函数（映射）。使用我们用来近似映射函数的（输入，输出）对训练集来完成学习。监督学习问题进一步分为分类和回归问题。在分类问题中，我们尝试预测示例所属的类，例如用户是否要点击广告。另一方面，回归问题是关于预测（实际）数值，通常称为因变量，例如明天的温度。

* Unsupervised Learning

  无监督学习涉及发现数据中的模式和规律。这方面的一个例子是聚类，我们尝试从描述性特征中发现数据的分组。无监督学习也可用于特征选择，例如通过主成分分析。

##  Flink-ML支持的算法

### Supervised Learning

- SVM

  SVM(Support Vector Machine)算法，即支持向量机算法，它是最优秀的分类算法之一，也是数据挖掘十大算法之一，它以其简单的理论构造了复杂的算法，又以其简单的用法实现了复杂的问题而受到业界的青睐。SVM算法属于有监督学习算法。它是在1995年由Corinna Cortes和Vapnik首先提出的。 

  SVM算法是基于统计学习理论的一种机器学习方法，它通过寻求结构化风险最小来提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。如今它常用来对小样本、非线性及高维数据进行模式识别、分类以及回归分析，并可以取得很好的效果。 

- Multiple linear regression

  多元线性回归试图找到最适合所提供输入数据的线性函数。 给定一组具有其值（x，y）的输入数据，多元线性回归找到向量w，使得残差平方的总和最小化：

  S(w)=∑i=1(y−wTxi)2

- Optimization Framework

  FlinkML中的优化框架是面向开发人员的包，可用于解决机器学习（ML）任务中常见的优化问题。 在监督学习环境中，这通常涉及找到由一组参数w定义的模型，该模型在给定一组（x，y）示例的情况下最小化函数f（w），其中x是特征向量并且y是 一个实数，可以表示回归情况下的实际值，也可以表示分类情况下的类标签。 在监督学习中，要最小化的功能通常是以下形式：

  f（w）：=1nΣi= 1nL（w; xi，yi）+λR（w）。（1）
  其中L是损失函数，R（w）是正则化罚分。 我们使用L来衡量模型与观测数据的拟合程度，并且我们使用R来为模型施加复杂性成本，λ> 0是正则化参数。

### Unsupervised Learning

- k-Nearest neighbors

  最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。

  KNN是通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

### Data Preprocessing

- Polynomial Features

  Polynomial Features是用于构建特征的，多项式特征变换器将矢量映射到度数为d的多项式特征空间中。 输入向量的维数确定多项式因子的数量，其值是相应的向量条目。 给定向量（x，y，z，...）T，得到的特征向量如下所示：

  (x,y,z,x2,xy,y2,yz,z2,x3,x2y,x2z,xy2,xyz,xz2,y3,…)

- Standard Scaler

  标准缩放器缩放给定的数据集，以便所有要素都具有用户指定的均值和方差。 如果用户没有提供特定的平均值和标准偏差，标准缩放器会将输入数据集的特征转换为平均值等于0且标准差等于1。

- MinMax Scaler

  MinMax缩放器缩放给定的数据集，以便所有值都位于用户指定的范围[min，max]之间。 如果用户没有为缩放范围提供特定的最小值和最大值，MinMax缩放器会将输入数据集的特征转换为[0,1]间隔。

### Recommendation

- Alternating Least Squares (ALS)

  ALS算法是基于模型的推荐算法。起基本思想是对稀疏矩阵进行模型分解，评估出缺失项的值，以此来得到一个基本的训练模型。然后依照此模型可以针对新的用户和物品数据进行评估。ALS是采用交替的最小二乘法来算出缺失项的。交替的最小二乘法是在最小二乘法的基础上发展而来的。由于本人数学有限，就大体的介绍下最小二乘法的思想。

### Outlier selection

- Stochastic Outlier Selection (SOS)

  异常值是一个或多个观察值，它们与大多数数据集定量偏离，可能是进一步调查的主题。 由[Jeroen Janssens ](http://jeroenjanssens.com/2013/11/24/stochastic-outlier-selection.html)开发的随机异常值选择（SOS）是一种无监督的离群值选择算法，它将一组向量作为输入。 该算法应用基于亲和力的离群值选择，并为每个数据点输出异常值概率。 直观地，当其他数据点与它的亲和力不足时，数据点被认为是异常值。

  异常值检测在许多领域都有应用，例如，日志分析，欺诈检测，噪声消除，新颖性检测，质量控制，传感器监测等。如果传感器出现故障，很可能会输出偏离的值 明显地来自多数人。

### Utilities

- Distance Metrics

  不同的距离度量对于不同类型的分析是便利的。 Flink ML为许多标准距离指标提供内置实现。 您可以通过实施DistanceMetric特征来创建自定义距离指标。

- Cross Validation

  当使用机器学习算法时，一个普遍存在的问题是过度拟合，或者当算法“记忆”训练数据但是在外推到样本案例之外做得很差。 处理过度拟合问题的常用方法是阻止原始训练算法中的某些数据子集，然后测量拟合算法在该保持集上的性能。 这通常称为交叉验证。 在一个数据子集上训练模型，然后在另一组数据上进行验证。

## 小结

本章概要介绍了Apache Flink ML模块信息以及目前Flink ML所支持的算法.

