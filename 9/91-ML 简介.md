# 9.1 Apache Flink ML 简介

## 什么是Flink-ML

Apache FlinkML是Flink的机器学习(ML)库, 对应Apache Flink代码的flink-libraries/flink-ml模块。 FlinkML的目标是提供可扩展的ML算法，直观的API和工具，以最小的陈本构建端到端ML系统。

## Flink-ML 算法分类

正如Murphy [1]所定义的那样，ML涉及检测数据中的模式，并使用这些学习模式来预测未来。我们可以将大多数ML算法分为两大类：监督和非监督学习。

* Supervised Learning

  监督学习涉及学习从一组输入（特征）到一组输出的函数（映射）。使用我们用来近似映射函数的（输入，输出）对训练集来完成学习。监督学习问题进一步分为分类和回归问题。在分类问题中，我们尝试预测示例所属的类，例如用户是否要点击广告。另一方面，回归问题是关于预测（实际）数值，通常称为因变量，例如明天的温度。

* Unsupervised Learning

  无监督学习涉及发现数据中的模式和规律。这方面的一个例子是聚类，我们尝试从描述性特征中发现数据的分组。无监督学习也可用于特征选择，例如通过主成分分析。

##  Flink-ML支持的算法

### Supervised Learning

- SVM

  SVM(Support Vector Machine)算法，即支持向量机算法，它是最优秀的分类算法之一，也是数据挖掘十大算法之一，它以其简单的理论构造了复杂的算法，又以其简单的用法实现了复杂的问题而受到业界的青睐。SVM算法属于有监督学习算法。它是在1995年由Corinna Cortes和Vapnik首先提出的。 

  SVM算法是基于统计学习理论的一种机器学习方法，它通过寻求结构化风险最小来提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。如今它常用来对小样本、非线性及高维数据进行模式识别、分类以及回归分析，并可以取得很好的效果。 

- Multiple linear regression

  多元线性回归试图找到最适合所提供输入数据的线性函数。 给定一组具有其值（x，y）的输入数据，多元线性回归找到向量w，使得残差平方的总和最小化：

  S(w)=∑i=1(y−wTxi)2

- Optimization Framework

  FlinkML中的优化框架是面向开发人员的包，可用于解决机器学习（ML）任务中常见的优化问题。 在监督学习环境中，这通常涉及找到由一组参数w定义的模型，该模型在给定一组（x，y）示例的情况下最小化函数f（w），其中x是特征向量并且y是 一个实数，可以表示回归情况下的实际值，也可以表示分类情况下的类标签。 在监督学习中，要最小化的功能通常是以下形式：

  f（w）：=1nΣi= 1nL（w; xi，yi）+λR（w）。（1）
  其中L是损失函数，R（w）是正则化罚分。 我们使用L来衡量模型与观测数据的拟合程度，并且我们使用R来为模型施加复杂性成本，λ> 0是正则化参数。

### Unsupervised Learning

- k-Nearest neighbors join

  最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。

  KNN是通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

### Data Preprocessing

- Polynomial Features

  Polynomial Features是用于构建特征的，多项式特征变换器将矢量映射到度数为d的多项式特征空间中。 输入向量的维数确定多项式因子的数量，其值是相应的向量条目。 给定向量（x，y，z，...）T，得到的特征向量如下所示：

  (x,y,z,x2,xy,y2,yz,z2,x3,x2y,x2z,xy2,xyz,xz2,y3,…)

- Standard Scaler

  标准缩放器缩放给定的数据集，以便所有要素都具有用户指定的均值和方差。 如果用户没有提供特定的平均值和标准偏差，标准缩放器会将输入数据集的特征转换为平均值等于0且标准差等于1。

- MinMax Scaler

  MinMax缩放器缩放给定的数据集，以便所有值都位于用户指定的范围[min，max]之间。 如果用户没有为缩放范围提供特定的最小值和最大值，MinMax缩放器会将输入数据集的特征转换为[0,1]间隔。

### Recommendation

- Alternating Least Squares (ALS)

  ALS算法是基于模型的推荐算法。起基本思想是对稀疏矩阵进行模型分解，评估出缺失项的值，以此来得到一个基本的训练模型。然后依照此模型可以针对新的用户和物品数据进行评估。ALS是采用交替的最小二乘法来算出缺失项的。交替的最小二乘法是在最小二乘法的基础上发展而来的。由于本人数学有限，就大体的介绍下最小二乘法的思想。

### Outlier selection

- Stochastic Outlier Selection (SOS)

  异常值是一个或多个观察值，它们与大多数数据集定量偏离，可能是进一步调查的主题。 由[Jeroen Janssens ](http://jeroenjanssens.com/2013/11/24/stochastic-outlier-selection.html)开发的随机异常值选择（SOS）是一种无监督的离群值选择算法，它将一组向量作为输入。 该算法应用基于亲和力的离群值选择，并为每个数据点输出异常值概率。 直观地，当其他数据点与它的亲和力不足时，数据点被认为是异常值。

  异常值检测在许多领域都有应用，例如，日志分析，欺诈检测，噪声消除，新颖性检测，质量控制，传感器监测等。如果传感器出现故障，很可能会输出偏离的值 明显地来自多数人。

### Utilities

- Distance Metrics

  不同的距离度量对于不同类型的分析是便利的。 Flink ML为许多标准距离指标提供内置实现。 您可以通过实施DistanceMetric特征来创建自定义距离指标。

- Cross Validation

  当使用机器学习算法时，一个普遍存在的问题是过度拟合，或者当算法“记忆”训练数据但是在外推到样本案例之外做得很差。 处理过度拟合问题的常用方法是阻止原始训练算法中的某些数据子集，然后测量拟合算法在该保持集上的性能。 这通常称为交叉验证。 在一个数据子集上训练模型，然后在另一组数据上进行验证。

## HelloWorld

###  ML依赖 

我还是直观的以代码的方式开始ML的学习之旅，首先是搭建环境。如果您是已经学习过第三章的Fink Helloworld小节，那么您已经具备了基本的Flink开发环境，进行ML的学习，只需要在Flink开发环境的基础上添加如下maven依赖：

```xml
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-ml_2.11</artifactId>
  <version>1.7.0</version>
</dependency>
```

### 数据加载

要加载要与FlinkML一起使用的数据，我们可以使用Flink的ETL功能，或者使用格式化数据的专用函数，例如LibSVM格式。对于监督学习问题，通常使用LabeledVector类来表示（标签，功能）示例。 LabeledVector对象将具有表示示例的功能的FlinkML Vector成员和表示标签的Double成员，该成员可以是分类问题中的类，或者是回归问题的因变量。

例如，我们可以使用Haberman的生存数据集，对应源代码工程的rhaberman.data文件。该数据集“包含对接受过乳腺癌手术的患者的生存进行的研究的病例”。数据以逗号分隔的文件形式出现，其中前3列是特征，最后一列是类，第4列表示患者是否存活了5年或更长时间（标签1），或者是否在5年内死亡（标签） 2）我们创建HelloWorld类，并加载haberman.data数据，并将数据转换为DataSet [LabeledVector]如下:

```scala
import org.apache.flink.api.scala._
import org.apache.flink.api.scala.ExecutionEnvironment
import org.apache.flink.ml.common.LabeledVector
import org.apache.flink.ml.math.DenseVector

object ETLLoadData {
  def main(args: Array[String]): Unit = {
    val env = ExecutionEnvironment.getExecutionEnvironment
        // 加载测试数据
        val survival = env.readCsvFile[(String, String, String, String)]("src/main/resources/haberman.data")
        
      // 构建我们需要的LabeledVector数据结构
      //数据集的第4个元素是类标签，其余的是要素，所以我们可以像这样构建LabeledVector元素：
      val survivalLV =
          survival
          .map { tuple =>
            val list = tuple.productIterator.toList
            val numList = list.map(_.asInstanceOf[String].toDouble)
            LabeledVector(numList(3), DenseVector(numList.take(3).toArray))
          }
  }
}
```

获得了上面的DataSet之后，我们就可以使用这些数据来培训学习者了。

###  HelloWorld

 接下来我们将使用另一个数据集来例证构建学习者; 并且用LibSVM的方式创建学习者数据集。LibSVM是ML数据集的通用格式，可以在LibSVM数据集[网站](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/）中找到使用该格式的许多数据集。 FlinkML提供了通过MLUtils对象提供的readLibSVM函数使用LibSVM格式加载数据集的实用程序。 您还可以使用writeLibSVM函数以LibSVM格式保存数据集。 让我们导入svmguide1数据集,对应训练集合svmguide1.data和测试集合svmguide1.t 。这是一个astroparticle二元分类数据集。我们创建HelloWorld主类并加载数据，代码如下：

```scala
package org.apache.flink.book.ml

import org.apache.flink.api.scala._
import org.apache.flink.ml.common.LabeledVector
import org.apache.flink.ml.MLUtils
import org.apache.flink.ml.classification.SVM
import org.apache.flink.ml.math.Vector

object HelloWorld {

  def main(args: Array[String]): Unit = {

    val env = ExecutionEnvironment.getExecutionEnvironment
    // 加载训练集合
    val astroTrainLibSVM: DataSet[LabeledVector] = MLUtils.readLibSVM(env, "src/main/resources/svmguide1.data")
    // 加载测试集合
    val astroTestLibSVM: DataSet[LabeledVector] = MLUtils.readLibSVM(env, "src/main/resources/svmguide1.t")
  }

}

```

这里简单说明一下libsvm的数据格式，libsvm使用的训练数据和检验数据文件格式如下：

```scala
[label] [index1]:[value1] [index2]:[value2] …
[label] [index1]:[value1] [index2]:[value2] …
```

* label  - 目标值，就是说class（属于哪一类），就是你要分类的种类，通常是一些整数。
* index -  是有顺序的索引，通常是连续的整数。就是指特征编号，必须按照升序排列
* value - 就是特征值，用来train的数据，通常是一堆实数组成。

也就是

```
目标值 第一维特征编号：第一维特征值   第二维特征编号：第二维特征值 …
目标值 第一维特征编号：第一维特征值   第二维特征编号：第二维特征值 …
```

我们看一下上面我们加载的train数据片段：

```
1 1:2.617300e+01 2:5.886700e+01 3:-1.894697e-01 4:1.251225e+02
```

表示训练特征有4维，第一维是2.617300e+01，第二维是5.886700e+01，第三维是-1.894697e-01，第四维是1.251225e+0  目标值是1 。

好当我们了解了基本的数据结构之后接下来我们利用上面的训练集合和测试集合继续一个简单的分类学习(Classification)。导入训练和测试数据集后，需要为分类做好准备。 由于Flink SVM仅支持+1.0和-1.0的阈值二进制值，因此在加载LibSVM数据集后需要进行转换，因为它使用1和0进行标记。可以使用简单的规范化器映射函数完成转换：

```scala
def normalizer : LabeledVector => LabeledVector = { 
    lv => LabeledVector(if (lv.label > 0.0) 1.0 else -1.0, lv.vector)
}
val astroTrain: DataSet[LabeledVector] = astroTrainLibSVM.map(normalizer)
val astroTest: DataSet[(Vector, Double)] = astroTestLibSVM.map(normalizer).map(x => (x.vector, x.label))
```

现在我们转换了数据集，就可以训练预测器，例如线性SVM分类器。 我们可以为分类器设置许多参数。 这里我们设置Blocks参数，用于通过底层CoCoA算法使用来分割输入。正则化参数确定所应用的l2正则化的量，其用于避免过度拟合。 步长确定权重向量更新对下一个权重向量值的贡献。 此参数设置初始步长。

```scala
val svm = SVM()
  .setBlocks(env.getParallelism)
  .setIterations(100)// 进行100次迭代
  .setRegularization(0.001)
  .setStepsize(0.1)// 设置步长
  .setSeed(42)

svm.fit(astroTrain)
```

最后的完整代码如下：

```scala
package org.apache.flink.book.ml

import java.io.File

import org.apache.flink.core.fs.FileSystem
import org.apache.flink.api.scala._
import org.apache.flink.book.utils.CommonUtils
import org.apache.flink.ml.common.LabeledVector
import org.apache.flink.ml.MLUtils
import org.apache.flink.ml.classification.SVM
import org.apache.flink.ml.math.Vector

object HelloWorld {

  def main(args: Array[String]): Unit = {

    val env = ExecutionEnvironment.getExecutionEnvironment
    env.setParallelism(1)
    // 加载训练集合
    val trainLibSVM: DataSet[LabeledVector] = MLUtils.readLibSVM(env, "src/main/resources/svmguide1.data")
    // 加载测试集合
    val testLibSVM: DataSet[LabeledVector] = MLUtils.readLibSVM(env, "src/main/resources/svmguide1.t")

    def normalizer: LabeledVector => LabeledVector = {
      lv =>
        LabeledVector(if (lv.label > 0.0) {
          1.0
        } else {
          -1.0
        }, lv.vector)
    }

    val astroTrain: DataSet[LabeledVector] = trainLibSVM.map(normalizer)
    val astroTest: DataSet[(Vector, Double)] =
      testLibSVM.map(normalizer).map(x => (x.vector, x.label))

    val svm = SVM() // 创建学习者
      .setBlocks(env.getParallelism)// 数据分块
      .setIterations(100) // 进行100次迭代
      .setRegularization(0.001) // 定义SVM算法的正则化常数。 值越高，权重向量的2-norm越小。
      .setStepsize(0.1) //定义权重向量更新的初始步长。 步长越大，权重向量更新对下一个权重向量值的贡献越大。 如果算法变得不稳定，则必须调整该值。 （默认值：1.0）
      .setSeed(42) // 初始化随机生成数种子

    // 模型学习
    svm.fit(astroTrain)

    //通过计算预测值并返回一对真实标签值和预测值来评估测试数据。 重要的是，实现选择一个Testing类型，从中可以提取真正的标签值。
    val evaluationPairs: DataSet[(Double, Double)] = svm.evaluate(astroTest)
    val tempFile = File.createTempFile("flink_ml", "tmp").getAbsolutePath
    evaluationPairs.writeAsCsv(tempFile, CommonUtils.line, " ", FileSystem.WriteMode.OVERWRITE)
    println("print the result by run cmd [ cat "+ tempFile + " ]" )

    env.execute()

  }

}

```

 上面代码不用有特别细致的理解，后面会有SVM的小结进行详细介绍。

## 小结

本章概要介绍了Apache Flink ML模块信息以及目前Flink ML所支持的算法，然后介绍了两种加载数据的方式之后，以一个SVM的分类算法体验了第一个Flink ML的示例。

